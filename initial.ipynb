{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch-geometric\n",
      "  Downloading torch_geometric-2.6.1-py3-none-any.whl.metadata (63 kB)\n",
      "Requirement already satisfied: aiohttp in /home/nikki/anaconda3/envs/neural_clbf2/lib/python3.10/site-packages (from torch-geometric) (3.11.10)\n",
      "Requirement already satisfied: fsspec in /home/nikki/anaconda3/envs/neural_clbf2/lib/python3.10/site-packages (from torch-geometric) (2024.6.1)\n",
      "Requirement already satisfied: jinja2 in /home/nikki/.local/lib/python3.10/site-packages (from torch-geometric) (3.1.2)\n",
      "Requirement already satisfied: numpy in /home/nikki/.local/lib/python3.10/site-packages (from torch-geometric) (1.26.2)\n",
      "Requirement already satisfied: psutil>=5.8.0 in /home/nikki/.local/lib/python3.10/site-packages (from torch-geometric) (5.9.6)\n",
      "Requirement already satisfied: pyparsing in /home/nikki/anaconda3/envs/neural_clbf2/lib/python3.10/site-packages (from torch-geometric) (3.1.2)\n",
      "Requirement already satisfied: requests in /home/nikki/.local/lib/python3.10/site-packages (from torch-geometric) (2.31.0)\n",
      "Requirement already satisfied: tqdm in /home/nikki/anaconda3/envs/neural_clbf2/lib/python3.10/site-packages (from torch-geometric) (4.67.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /home/nikki/anaconda3/envs/neural_clbf2/lib/python3.10/site-packages (from aiohttp->torch-geometric) (2.4.6)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/nikki/anaconda3/envs/neural_clbf2/lib/python3.10/site-packages (from aiohttp->torch-geometric) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/nikki/.local/lib/python3.10/site-packages (from aiohttp->torch-geometric) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/nikki/anaconda3/envs/neural_clbf2/lib/python3.10/site-packages (from aiohttp->torch-geometric) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/nikki/anaconda3/envs/neural_clbf2/lib/python3.10/site-packages (from aiohttp->torch-geometric) (6.0.5)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /home/nikki/anaconda3/envs/neural_clbf2/lib/python3.10/site-packages (from aiohttp->torch-geometric) (0.2.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /home/nikki/anaconda3/envs/neural_clbf2/lib/python3.10/site-packages (from aiohttp->torch-geometric) (1.18.0)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /home/nikki/anaconda3/envs/neural_clbf2/lib/python3.10/site-packages (from aiohttp->torch-geometric) (4.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/nikki/.local/lib/python3.10/site-packages (from jinja2->torch-geometric) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/nikki/.local/lib/python3.10/site-packages (from requests->torch-geometric) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/nikki/.local/lib/python3.10/site-packages (from requests->torch-geometric) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/nikki/.local/lib/python3.10/site-packages (from requests->torch-geometric) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/nikki/.local/lib/python3.10/site-packages (from requests->torch-geometric) (2023.11.17)\n",
      "Downloading torch_geometric-2.6.1-py3-none-any.whl (1.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: torch-geometric\n",
      "Successfully installed torch-geometric-2.6.1\n"
     ]
    }
   ],
   "source": [
    "!pip install torch-geometric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import MessagePassing\n",
    "from torch_geometric.utils import add_self_loops, degree\n",
    "def hebbian_update(weight, pre_activation, post_activation, learning_rate):\n",
    "    delta_w = learning_rate * torch.outer(post_activation, pre_activation)\n",
    "    return weight + delta_w\n",
    "\n",
    "def hebbian_update_with_oja(weight, pre_activation, post_activation, learning_rate):\n",
    "    delta_w = learning_rate * torch.outer(post_activation, pre_activation)\n",
    "    weight = weight + delta_w\n",
    "    weight = weight / torch.norm(weight, p=2)  # Normalize to prevent explosion\n",
    "    return weight\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import numpy as np\n",
    "\n",
    "def create_grid_graph(width, height, blocked_positions):\n",
    "    G = nx.grid_2d_graph(width, height)\n",
    "    mapping = {node: i for i, node in enumerate(G.nodes())}\n",
    "    G = nx.relabel_nodes(G, mapping)\n",
    "\n",
    "    for pos in blocked_positions:\n",
    "        if pos in mapping:\n",
    "            G.remove_node(mapping[pos])\n",
    "\n",
    "    return G, mapping  # Return mapping for agent indexing\n",
    "\n",
    "width, height = 10, 10\n",
    "blocked_positions = [(1, 1), (2, 2), (3, 3)]\n",
    "graph,mapping = create_grid_graph(width, height, blocked_positions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "class Agent:\n",
    "    def __init__(self, start, goal):\n",
    "        self.start = start\n",
    "        self.goal = goal\n",
    "        self.position = start\n",
    "\n",
    "def initialize_agents(num_agents, graph, mapping):\n",
    "    nodes = list(graph.nodes)\n",
    "    agents = []\n",
    "    used_positions = set()\n",
    "\n",
    "    for _ in range(num_agents):\n",
    "        start = random.choice(nodes)\n",
    "        while start in used_positions:\n",
    "            start = random.choice(nodes)\n",
    "        used_positions.add(start)\n",
    "\n",
    "        goal = random.choice(nodes)\n",
    "        while goal in used_positions:\n",
    "            goal = random.choice(nodes)\n",
    "        used_positions.add(goal)\n",
    "\n",
    "        agents.append(Agent(start, goal))\n",
    "\n",
    "    return agents\n",
    "\n",
    "\n",
    "num_agents = 5\n",
    "agents = initialize_agents(num_agents, graph,mapping)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0,  0,  1,  2,  2,  3,  3,  4,  4,  5,  5,  6,  6,  7,  7,  8,  8,  9,\n",
      "         10, 12, 13, 13, 14, 14, 15, 15, 16, 16, 17, 17, 18, 18, 19, 20, 20, 21,\n",
      "         23, 24, 24, 25, 25, 26, 26, 27, 27, 28, 28, 29, 30, 30, 31, 31, 32, 34,\n",
      "         34, 35, 35, 36, 36, 37, 37, 38, 38, 39, 40, 40, 41, 41, 42, 42, 43, 43,\n",
      "         44, 44, 45, 45, 46, 46, 47, 47, 48, 48, 49, 50, 50, 51, 51, 52, 52, 53,\n",
      "         53, 54, 54, 55, 55, 56, 56, 57, 57, 58, 58, 59, 60, 60, 61, 61, 62, 62,\n",
      "         63, 63, 64, 64, 65, 65, 66, 66, 67, 67, 68, 68, 69, 70, 70, 71, 71, 72,\n",
      "         72, 73, 73, 74, 74, 75, 75, 76, 76, 77, 77, 78, 78, 79, 80, 80, 81, 81,\n",
      "         82, 82, 83, 83, 84, 84, 85, 85, 86, 86, 87, 87, 88, 88, 89, 90, 91, 92,\n",
      "         93, 94, 95, 96, 97, 98],\n",
      "        [10,  1,  2, 12,  3, 13,  4, 14,  5, 15,  6, 16,  7, 17,  8, 18,  9, 19,\n",
      "         20, 13, 23, 14, 24, 15, 25, 16, 26, 17, 27, 18, 28, 19, 29, 30, 21, 31,\n",
      "         24, 34, 25, 35, 26, 36, 27, 37, 28, 38, 29, 39, 40, 31, 41, 32, 42, 44,\n",
      "         35, 45, 36, 46, 37, 47, 38, 48, 39, 49, 50, 41, 51, 42, 52, 43, 53, 44,\n",
      "         54, 45, 55, 46, 56, 47, 57, 48, 58, 49, 59, 60, 51, 61, 52, 62, 53, 63,\n",
      "         54, 64, 55, 65, 56, 66, 57, 67, 58, 68, 59, 69, 70, 61, 71, 62, 72, 63,\n",
      "         73, 64, 74, 65, 75, 66, 76, 67, 77, 68, 78, 69, 79, 80, 71, 81, 72, 82,\n",
      "         73, 83, 74, 84, 75, 85, 76, 86, 77, 87, 78, 88, 79, 89, 90, 81, 91, 82,\n",
      "         92, 83, 93, 84, 94, 85, 95, 86, 96, 87, 97, 88, 98, 89, 99, 91, 92, 93,\n",
      "         94, 95, 96, 97, 98, 99]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch_geometric.utils import from_scipy_sparse_matrix\n",
    "\n",
    "def get_edge_index(graph):\n",
    "    edge_index = torch.tensor(list(graph.edges), dtype=torch.long).t().contiguous()\n",
    "    return edge_index\n",
    "\n",
    "edge_index = get_edge_index(graph)\n",
    "print(edge_index)\n",
    "# adj_matrix = torch.tensor(adj_matrix)\n",
    "# edge_index = adj_matrix.nonzero(as_tuple=False).t().contiguous()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv,SAGEConv\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "class GNNPolicy(torch.nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(GNNPolicy, self).__init__()\n",
    "\n",
    "        self.conv1 = GCNConv(input_dim, hidden_dim)\n",
    "        self.conv2 = GCNConv(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        print(x.shape)\n",
    "        print(edge_index.shape)\n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "# Example usage\n",
    "input_dim = 2  # e.g., agent position and goal position\n",
    "hidden_dim = edge_index.shape[1]\n",
    "output_dim = 5  # up, down, left, right, stay\n",
    "policy_net = GNNPolicy(input_dim, hidden_dim, output_dim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_nodes = graph.number_of_nodes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "optimizer = optim.Adam(policy_net.parameters(), lr=0.01)\n",
    "\n",
    "def select_action(state, policy_net, edge_index):\n",
    "    state_tensor = torch.tensor(state, dtype=torch.float)\n",
    "    data = Data(x=state_tensor, edge_index=edge_index)\n",
    "\n",
    "    print(data.x.shape, data.edge_index.shape)\n",
    "    print(type(state))\n",
    "    probs = policy_net(data)\n",
    "    m = torch.distributions.Categorical(probs[state])  # Get action for this agent\n",
    "    action = m.sample()\n",
    "    \n",
    "    return action.item(), m.log_prob(action)\n",
    "\n",
    "\n",
    "def update_policy(policy_net, optimizer, log_probs, rewards, gamma=0.99):\n",
    "    discounted_rewards = []\n",
    "    R = 0\n",
    "    for r in rewards[::-1]:\n",
    "        R = r + gamma * R\n",
    "        discounted_rewards.insert(0, R)\n",
    "    discounted_rewards = torch.tensor(discounted_rewards)\n",
    "    discounted_rewards = (discounted_rewards - discounted_rewards.mean()) / (discounted_rewards.std() + 1e-5)\n",
    "    policy_loss = []\n",
    "    for log_prob, reward in zip(log_probs, discounted_rewards):\n",
    "        policy_loss.append(-log_prob * reward)\n",
    "    optimizer.zero_grad()\n",
    "    policy_loss = torch.cat(policy_loss).sum()\n",
    "    policy_loss.backward()\n",
    "    optimizer.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2]) torch.Size([2, 168])\n",
      "<class 'list'>\n",
      "torch.Size([2])\n",
      "torch.Size([2, 168])\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "Dimension out of range (expected to be in range of [-1, 0], but got -2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[217], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m agent \u001b[38;5;129;01min\u001b[39;00m agents:\n\u001b[1;32m      7\u001b[0m     state \u001b[38;5;241m=\u001b[39m [agent\u001b[38;5;241m.\u001b[39mposition, agent\u001b[38;5;241m.\u001b[39mgoal]\n\u001b[0;32m----> 8\u001b[0m     action, log_prob \u001b[38;5;241m=\u001b[39m \u001b[43mselect_action\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpolicy_net\u001b[49m\u001b[43m,\u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m     log_probs\u001b[38;5;241m.\u001b[39mappend(log_prob)\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;66;03m# Execute action and observe reward\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[216], line 11\u001b[0m, in \u001b[0;36mselect_action\u001b[0;34m(state, policy_net, edge_index)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(data\u001b[38;5;241m.\u001b[39mx\u001b[38;5;241m.\u001b[39mshape, data\u001b[38;5;241m.\u001b[39medge_index\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mtype\u001b[39m(state))\n\u001b[0;32m---> 11\u001b[0m probs \u001b[38;5;241m=\u001b[39m \u001b[43mpolicy_net\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m m \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdistributions\u001b[38;5;241m.\u001b[39mCategorical(probs[state])  \u001b[38;5;66;03m# Get action for this agent\u001b[39;00m\n\u001b[1;32m     13\u001b[0m action \u001b[38;5;241m=\u001b[39m m\u001b[38;5;241m.\u001b[39msample()\n",
      "File \u001b[0;32m~/anaconda3/envs/neural_clbf2/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[210], line 17\u001b[0m, in \u001b[0;36mGNNPolicy.forward\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(x\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(edge_index\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m---> 17\u001b[0m x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     18\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv2(x, edge_index)\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mlog_softmax(x, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/neural_clbf2/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/neural_clbf2/lib/python3.10/site-packages/torch_geometric/nn/conv/gcn_conv.py:242\u001b[0m, in \u001b[0;36mGCNConv.forward\u001b[0;34m(self, x, edge_index, edge_weight)\u001b[0m\n\u001b[1;32m    239\u001b[0m cache \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cached_edge_index\n\u001b[1;32m    240\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    241\u001b[0m     edge_index, edge_weight \u001b[38;5;241m=\u001b[39m gcn_norm(  \u001b[38;5;66;03m# yapf: disable\u001b[39;00m\n\u001b[0;32m--> 242\u001b[0m         edge_index, edge_weight, \u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnode_dim\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m    243\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimproved, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_self_loops, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mflow, x\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[1;32m    244\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcached:\n\u001b[1;32m    245\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cached_edge_index \u001b[38;5;241m=\u001b[39m (edge_index, edge_weight)\n",
      "\u001b[0;31mIndexError\u001b[0m: Dimension out of range (expected to be in range of [-1, 0], but got -2)"
     ]
    }
   ],
   "source": [
    "num_episodes = 1000\n",
    "\n",
    "for episode in range(num_episodes):\n",
    "    log_probs = []\n",
    "    rewards = []\n",
    "    for agent in agents:\n",
    "        state = [agent.position, agent.goal]\n",
    "        action, log_prob = select_action(state, policy_net,edge_index)\n",
    "        log_probs.append(log_prob)\n",
    "        # Execute action and observe reward\n",
    "        reward = 0\n",
    "        \n",
    "        # Goal achievement\n",
    "        if agent.position == agent.goal:\n",
    "            reward += 10\n",
    "        \n",
    "        # Collision penalty\n",
    "        for other_agent in agents:\n",
    "            if other_agent != agent and agent.position == other_agent.position:\n",
    "                reward -= 5\n",
    "        \n",
    "        # Step penalty\n",
    "        reward -= 1\n",
    "        # Update agent position based on action\n",
    "        # Compute reward based on new state\n",
    "        rewards.append(reward)\n",
    "    update_policy(policy_net, optimizer, log_probs, rewards)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neural_clbf2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
